---
title: "IDS572_Assignment1_PartA"
author: "Garima Agarwal, Roshinder Virdee, Sai Nischith Vangala"
date: "2/14/2021"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 2. Data Exploration

```{r, message=FALSE}

##load libraries##
library(magrittr)
library(dplyr)  
library(ggplot2)
library(tidyverse)
library(ggplotgui)
library(shiny)
library(lubridate)
library(pROC)
library(broom)
library(rpart)

## READ FILE INTO R ##
lcdfdf <- read.csv('C:/Users/user/Desktop/UIC MSBA/IDS 572 Data Mining for Business/lcDataSample5m.csv')

lcdf <- lcdfdf
# View(lcdfdf)



```

** Q2:**

- **(i) What is the proportion of defaults (‘charged off’ vs ‘fully paid’ loans) in the data?**
```{r proportionDef}


#How many loans are fully-paid and charged-off?
lcdfdf %>% group_by(loan_status) %>% tally()
  #are there values for loan_status other than "Fully Paid' and "Charged Off"?  If so, remove them:
lcdfdf <- lcdfdf %>% filter(loan_status == "Fully Paid" | loan_status == "Charged Off")

#view table with counts for each loan status
table(lcdfdf$loan_status)

#view table in percentage values
lcdfdf$loan_status %>% table() %>% prop.table() %>% `*`(100) %>% round(2)


#How does loan status vary by loan grade
table(lcdfdf$loan_status, lcdfdf$grade)


#How does loan status vary by loan sub grade
table(lcdfdf$loan_status, lcdfdf$sub_grade)

#Loan amount vary by grade
lcdfdf %>% group_by(grade) %>% tally() %>% view()


#Some summarized info on loans by grade
lcdfdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt)) %>% view()

#Loan Vary with Purpose
table(lcdfdf$purpose)
head(lcdfdf) %>% view()
#summarize by grade
lcdf %>% group_by(grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt), avgRet=mean(annRet), stdRet=sd(annRet), minRet=min(annRet), maxRet=max(annRet))

#summarize by grade, Sub_Grade
lcdf %>% group_by(grade,sub_grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt)) %>% view()

#Some summarized info on loans by purpose
lcdf %>% group_by(purpose,grade) %>% summarise(nLoans=n(), defaults=sum(loan_status=="Charged Off"), avgInterest= mean(int_rate), stdInterest=sd(int_rate), avgLoanAMt=mean(loan_amnt), avgPmnt=mean(total_pymnt)) %>% view()

#Do defaults vary by purpose
lcdf %>% 
group_by(purpose) %>% summarise(nLoans=n(),defaults=sum(loan_status=="Charged Off"),percent_defaults=defaults/nLoans*100) %>% arrange(percent_defaults)%>% view()

loanStatGrade <-table(lcdf$loan_status, lcdf$grade)
prop.table(loanStatGrade, 2) %>% `*`(100) %>% round(2)

  loanStatSubGrade <-table(lcdf$loan_status, lcdf$sub_grade)
  prop.table(loanStatSubGrade, 2) %>% `*`(100) %>% round(2)


#barchart for loan freq
ggplot(lcdf,aes(x=factor(purpose)))+
  geom_bar(position="dodge")+ 
  labs(title="Number of loans per purpose", x="purpose", y = "Frequency")+
  geom_text(aes(label=..count..),stat='count',position=position_dodge(0.5),vjust=-0.2) +
  theme(axis.text.x = element_text(angle = 90))   


#(iv) For loans which are fully paid back, how does the time-to-full-payoff vary? For this, calcdfulate the ‘actual term’ (issue-date to last-payment-date) for all loans.**


#Concatenate -01 to last_pymt_d value
lcdf$last_pymnt_d<-paste(lcdf$last_pymnt_d, "-01", sep = "")

#Then convert this character to a date type variable

lcdf$last_pymnt_d<-parse_date_time(lcdf$last_pymnt_d,  "myd")
as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)
x<- as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)
head(x)

#Another issue to consider: what about those loans which are charged-off ? These are not paid back fully by the end of the 3-year term, so the duration as calcdfulated above will not give the accurate value for the actual-term. For these loans, we can set the actual-term at 3/
lcdf$actualTerm <- ifelse(lcdf$loan_status=="Fully Paid", as.duration(lcdf$issue_d  %--% lcdf$last_pymnt_d)/dyears(1), 3)

#Then, considering this actual term, the actual annual return is
lcdf$actualReturn <- ifelse(lcdf$actualTerm>0, ((lcdf$total_pymnt -lcdf$funded_amnt)/lcdf$funded_amnt)*(1/lcdf$actualTerm)*100, 0)

#create separate df for data with only Charged Off
lcdfNoDef <- lcdf
lcdfNoDef <- lcdfNoDef[ (lcdfNoDef$loan_status == "Fully Paid"), ]

#how does average actual term vary by grade for fully paid loans?
lcdfNoDef %>% group_by(grade) %>% summarise(nLoans=n(), avgActualTerm=mean(actualTerm))

```

```

- **(v) Calcdfulate the annual return. Show how you calcdfulate the percentage annual return. Is there any return from loans which are ‘charged off’? Explain**
```{r, annualReturn}

#Create variable for annual return with formula
lcdf$annRet <- ((lcdf$total_pymnt-lcdf$funded_amnt)/lcdf$funded_amnt)*(12/36)*100

#What is the avg int rate, and the avg return, total return, and avg actual return, and avg annual return grouped by loan_status
lcdf%>% group_by(loan_status) %>% summarise(  intRate=mean(int_rate), totRet=mean((total_pymnt-funded_amnt)/funded_amnt), avgActRet=mean(actualReturn), avgAnnRet=mean(annRet))


```

- **(v) How does return from charged - off loans vary by loan grade? Compare the average return values with the average interest_rate on loans – do you notice any differences, and how do you explain this? How do returns vary by grade, and by sub-grade.** 
``` {r}

#create separate df for data with only Charged Off
lcdfDef <- lcdf
lcdfDef <- lcdfDef[ (lcdfDef$loan_status == "Charged Off"), ]

#by grade
lcdfDef %>% group_by(grade) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)

#by sub-grade
lcdfDef %>% group_by(sub_grade) %>% summarise(nLoans=n(), avgInterest= mean(int_rate), avgLoanAmt=mean(loan_amnt), avgRet=mean(annRet), avgActualRet=mean(actualReturn)*100, avgActualTerm=mean(actualTerm),  minActualRet=min(actualReturn)*100, maxActualRet=max(actualReturn)*100)


```

- **(v) Generate some (at least 3) new derived attributes which you think may be useful for predicting default., and explain what these are.**

``` {r derivedAttributes}

#Derived attribute #1: proportion of total annual income per total term vs loan amount 
lcdf$propLoanAmtAnnInc <- ifelse(lcdf$annual_inc>0, (lcdf$loan_amnt/(lcdf$annual_inc*3)), 0)

#Derived attribute #2: proportion of open revolving accounts 
lcdf$propOpenRevAcc <- ifelse(lcdf$num_rev_accts>0, lcdf$num_op_rev_tl/lcdf$num_rev_accts, 0)

#Derived attribute #3: ratio of the accounts currently 120 days past due vs total accounts ever 120 days past due
lcdf$propAccPastDue120 <- ifelse(lcdf$num_tl_120dpd_2m>0, lcdf$num_tl_120dpd_2m/lcdf$num_accts_ever_120_pd, 0)

                               
```

**2b**
- **Are there missing values? What is the proportion of missing values in different variables? Explain how you will handle missing values for different variables. What is a sensible value to replace the missing values in this case? Are there some variables you will exclude from your model due to missing values?**

``` {r}
nrow(lcdf)
ncol(lcdf) # 146
colMeans(is.na(lcdf))
#check which columns have all missing values
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))==1]

#check which columns have any missing values more than 0 but less than 1
colMeans(is.na(lcdf))[colMeans(is.na(lcdf))>0 & colMeans(is.na(lcdf))<1]

#create a separate file for the removed data
lcdfdl <- data.frame(lcdf)

#drop the variables that have all empty values
lcdfdl <- lcdfdl %>% select_if(function(x){!all(is.na(x))})
#Drops vars with more than 60% 
nm<-names(lcdfdl)[colMeans(is.na(lcdfdl))>0.6]
lcdfdl <- lcdfdl %>% select(-nm)
nrow(lcdfdl)
#looking at the individual columns to see what their missing value counts are and stats
nm<- names(lcdfdl)[colSums(is.na(lcdfdl))>0]
summary(lcdfdl[, nm])

#replacing all columns with NA missing values with their median values or a much larger number
lcdfdl<- lcdfdl %>% replace_na(list(mths_since_last_delinq=500, revol_util=median(lcdfdl$revol_util, na.rm=TRUE), bc_open_to_buy=median(lcdfdl$bc_open_to_buy, na.rm=TRUE), mo_sin_old_il_acct=1000, mths_since_recent_bc=1000, mths_since_recent_inq=50, num_tl_120dpd_2m = median(lcdfdl$num_tl_120dpd_2m, na.rm=TRUE),percent_bc_gt_75 = median(lcdfdl$percent_bc_gt_75, na.rm=TRUE), bc_util=median(lcdfdl$bc_util, na.rm=TRUE) ))

#checking if we addressed all the columns with missing values
colMeans(is.na(lcdfdl))[colMeans(is.na(lcdfdl))>0]

#check the values of all rows with NA values for last_pymnt_d column
#lcdf %>% filter(is.na(lcdf$last_pymnt_d))

```

**3) Consider the potential for data leakage. You do not want to include variables in your model which may not be available when applying the model; that is, some data may not be available for new loans before they are funded. Leakage may also arise from variables in the data which may have been updated during the loan period (ie., after the loan is funded). Identify and explain which variables will you exclude from the model.**
```{r, dataLeak}

#  convert all of the columns with character values into factor instead
lcdfdl <- lcdfdl %>% mutate_if(is.character, as.factor)
ncol(lcdfdl)
names(lcdfdl)
lcd_bak <- lcdfdl
#lcdfdl <- lcd_bak
lcd_2 <- lcdfdl


#Drop some other columns which are not useful and those which will cause 'leakage' according to Professor Sid's file
names(lcd_2)

lcdfdl <- lcd_2 %>% select(-c(
X, funded_amnt, funded_amnt_inv,          
term,                                     
      emp_title, 
    issue_d,                
pymnt_plan,                 
title,                      
addr_state,                  
   
total_pymnt,                total_pymnt_inv,           
 total_rec_prncp,  total_rec_int,             
 total_rec_late_fee,         recoveries,                
collection_recovery_fee, last_pymnt_d,              
last_pymnt_amnt,            last_credit_pull_d,        
policy_code,  
application_type,           acc_now_delinq,            
tot_coll_amt, tot_cur_bal, hardship_flag, disbursement_method, debt_settlement_flag, zip_code, inq_last_6mths, mths_since_last_delinq,    open_acc,                  
pub_rec,                    revol_bal,                 
revol_util, total_acc, delinq_2yrs,   out_prncp_inv,


issue_d, purpose, addr_state, revol_util, recoveries, tot_cur_bal, bc_open_to_buy, bc_util
))


ncol(lcdfdl)
names(lcdfdl)

#removes all variables that we determined could cause data leakage
#lcdfdl <- lcdfdl %>% select (-c(hardship_flag, disbursement_method, debt_settlement_flag, initial_list_status, collection_recovery_fee, recoveries, collection_recovery_fee, last_pymnt_d, last_pymnt_amnt, total_pymnt))
ncol(lcdfdl)

names(lcdfdl)
lcdfdl
lcdfdl <- lcdfdl %>% select(c(
loan_amnt, int_rate, grade, loan_status, earliest_cr_line)  )
###########################################################

#Develop decision tree models to predict default.
#(a) Split the data into training and validation sets. What proportions do you consider, why?

library(rpart)
#summarize the lcdf
lcdf<- lcdfdl
summary(lcdf)

#created attribute 
#$ annRet                 : num  2.61 2.78 1.98 10.13 7.24 ...
#$ actualTerm             : num  1.76 3.09 1 3.09 3.09 ...
#$ actualReturn           : num  0.0445 0.0271 0.0594 0.0985 0.0704 ...
#$ ratio_annualinc_loanamt: num  14.86 11.88 4.99 3.33 3.57 ...
#$ ratio_install_loanamt  : num  0.0305 0.0301 0.0314 0.0363 0.0339 ...

ncol(lcdf)

#lcdfx <- subset(lcdf, #select=-c(annRet,actualTerm,actualReturn,ratio_annualinc_loanamt,ratio_insta#ll_loanamt))
#ncol(lcdfx) #49
#str(lcdfx)
# lcdfx is the backup dataframe

#lcdf <- lcdfx

#Ensure factor
str(lcdf)
lcdf= lcdf %>% mutate_if(is.character, as.factor)
str(lcdf)
dim(lcdf)

#Splitting Training Data set and Testing Data Set
nr=nrow(lcdf)
TRG_PCT=0.7
trnIndex = sample(1:nr, size = round(TRG_PCT*nr), replace=FALSE) 
lcdfTrn=lcdf[trnIndex,]   
lcdfTst = lcdf[-trnIndex,]

#Check Training and Testing size
nrow(lcdfTrn)
nrow(lcdfTst)

names(lcdfTrn)

#Model1 the decision tree (15 secs)
#rpModel1=rpart(loan_status ~ ., data=lcdfTrn, method="class")

#RPart minsplit = 5
lcDT1 <- rpart(loan_status ~., data=lcdfTrn, method="class", 
               parms = list(split = "information"), control = rpart.control(minsplit = 5))
print(lcDT1)
library(rpart.plot)
rpart.plot::prp(lcDT1, type=2, extra=1)

lcDT1$variable.importance
printcp(lcDT1)

#RPart minsplit = 50
lcDT2 <- rpart(loan_status ~., data=lcdfTrn, method="class", 
               parms = list(split = "information"), control = rpart.control(minsplit = 50))
print(lcDT2)
#plot the decision tree
library(rpart.plot)
rpart.plot::prp(lcDT2, type=2, extra=1)
summary(lcDT2)

lcDT3 <- rpart(loan_status ~., data=lcdfTrn, method="class", 
               parms = list(split = "information"), control = rpart.control(minsplit = 80))
print(lcDT3)


# Pruned tree
lcDT1p<- prune.rpart(lcDT1, cp=0.0003)  
print(lcDT1p)
library(rpart.plot)
rpart.plot::prp(lcDT1p, type=2, extra=1)

#Model2 > Select the best cp by observing the graph (1min)
#rpModel2 = rpart(loan_status ~ ., data=lcdfTrn, method="class", control = rpart.control(cp = 0.0))
#printcp(rpModel2)
#plotcp(rpModel2)

#Model2_pruned > Prune the tree ()
#rpModel2_pruned = prune(rpModel2, cp=0.0015)
#rpart.plot::prp(rpModel2_pruned, type=2, extra=1)

#Performance Evaluation Model1?
predTrn=predict(lcDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)  #0.9856477

#str(lcdfTst)
#levels(droplevels(lcdfTst$title))

table(pred = predict(lcDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcDT1,lcdfTst, type='class') ==lcdfTst$loan_status)  # 0.9838784

###################################################
#Performance Evaluation with different classification threshold
#print(predProbTrn[, 'Charged Off'])

CTHRESH=0.60
predProbTrn=predict(lcDT1,lcdfTrn, type='prob')
predTrnCT = ifelse(predProbTrn[, 'Charged Off'] > CTHRESH, 'Charged Off', 'Fully Paid')
table(predTrnCT , true=lcdfTrn$loan_status)
# Or, to set the predTrnCT values as factors, and then get the confusion matrix
table(predictions=factor(predTrnCT, levels=c("Fully Paid", "Charged Off")), actuals=lcdfTrn$loan_status)

#precision_recall_curve()

library(lattice)
library(ggplot2)
library(caret)
confusionMatrix(predTrn, lcdfTrn$loan_status)
confusionMatrix(predTrn, lcdfTrn$loan_status, positive="Charged Off")

# Accuracy : 0.9885

#confusionMatrix(pred, lcdfTst$loan_status)

##############################################
# C5.0
library(C50)
str(lcdfTrn)

#costMat <- matrix(c(0,23,37,0), nrow=2)

C5_DT1 <- C5.0(loan_status ~., data=lcdfTrn, control=C5.0Control(),rules=TRUE)
print(C5_DT1)
C5imp(C5_DT1) %>% view()

predTrn = predict(C5_DT1,lcdfTrn)
table(predTrn, lcdfTrn$loan_status)
predTst = predict(C5_DT1,lcdfTst)
table(predTst, lcdfTrn$loan_status)

ncol(lcdfTrn)

c_tree <- C5.0(as.factor(lcdfTrn$loan_status) ~., data = lcdfTrn, 
               method = "class", trials = 3, control=C5.0Control(CF=0.45,earlyStopping =FALSE))
print(c_tree)

##################ROCR##################
library('ROCR')
score=predict(lcDT1,lcdfTst, type="prob")[,"Charged Off"]
pred=prediction(score, lcdfTst$loan_status, label.ordering = c("Fully Paid", "Charged Off"))
#label.ordering here specifies the 'negative', 'positive' class labels   

#ROC curve
aucPerf <-performance(pred, "tpr", "fpr")
plot(aucPerf)
abline(a=0, b= 1)

#AUC value
aucPerf=performance(pred, "auc")
aucPerf@y.values

#Lift curve
liftPerf <-performance(pred, "lift", "rpp")
plot(liftPerf)

#############################################################
```

**4) Do a uni-variate analysis to determine which variables (from amongst those you decide to consider for the next stage prediction task) will be individually useful for predicting the dependent variable (loan_status).**
```{r analysis}

#split the data into trn, tst subsets
TRNFRACTION = 0.5 #or use other values
nr<-nrow(lcdfdl)

trnIndex<- sample(1:nr, size = round(TRNFRACTION * nr), replace=FALSE)
lcdfTrn <- lcdfdl[trnIndex, ]
lcdfTst <- lcdfdl[-trnIndex, ]

# For the numeric variables:
aucsNum<-sapply(lcdfTrn %>% select_if(is.numeric), auc, response=lcdfTrn$loan_status)


#Or considering both numeric and factor variables:
aucAll<- sapply(lcdfTrn %>% mutate_if(is.factor, as.numeric) %>% select_if(is.numeric), auc, response=lcdfTrn$loan_status) 

#To determine which variables have auc > 0.5, to ensure the variables selected are predicting loan_status better than random chance (50%)
aucAll[aucAll>0.5]

tidy(aucAll[aucAll > 0.5]) %>% view()

# or in sorted order
tidy(aucAll) %>% arrange(desc(aucAll))

```

```{r model}

#It can be useful to convert the target variable, loan_status to  a factor variable
lcdf$loan_status <- factor(lcdf$loan_status, levels=c("Fully Paid", "Charged Off"))


lcdfDT1 <- rpart(loan_status ~., data=lcdfTrn, method="class", parms = list(split = "information"), control = rpart.control(minsplit = 30))

lcdfDT1 <- rpart(loan_status ~., data=lcdfTrn, method="class", parms = list(split = "information"), control = rpart.control(cp=0.0001, minsplit = 50))


#Evaluate performance
predTrn=predict(lcdfDT1,lcdfTrn, type='class')
table(pred = predTrn, true=lcdfTrn$loan_status)
mean(predTrn == lcdfTrn$loan_status)
table(pred = predict(lcdfDT1,lcdfTst, type='class'), true=lcdfTst$loan_status)
mean(predict(lcdfDT1,lcdfTst, type='class') ==lcdfTst$loan_status)

```